{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fed8d40-7499-448f-9032-f04a553aec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"../../sac_ae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f1a07c1-e1fd-4583-9555-8758b3f12b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from ipywidgets import Output, GridspecLayout\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme()\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "947491b9-ef6a-47da-b3ad-d5165dbf5cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sac_ae.env import make_envs\n",
    "from sac_ae.model import make_model\n",
    "from sac_ae.agent import make_agent\n",
    "from utils.misc import eval_mode, VideoRecorder\n",
    "from utils.argument import Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02098fd7-5fab-4a5e-a3e4-fc3537979d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_agent_and_args(path, device=torch.device('cpu'), model_name='model/best_model.pt', cost_samples=None, cost_allowed_threshold=None):\n",
    "    args = Arguments(path + 'args.json')\n",
    "    weights = torch.load(path + model_name, map_location=device)\n",
    "    \n",
    "    if cost_samples != None:\n",
    "        args.cost_samples = cost_samples\n",
    "    if cost_allowed_threshold != None:\n",
    "        args.cost_allowed_threshold = cost_allowed_threshold\n",
    "    if args.agent == 'sac_state':\n",
    "        agent_obs_shape = weights['actor.encoder.projection.projection.0.weight'].shape[1:]\n",
    "        args.agent_image_size = agent_obs_shape[0]\n",
    "    else:\n",
    "        agent_obs_shape = (3*args.frame_stack, args.agent_image_size, args.agent_image_size)\n",
    "    action_shape = np.array([4])\n",
    "\n",
    "    model = make_model(agent_obs_shape, action_shape, args, device)\n",
    "    agent = make_agent(model, device, action_shape, args)\n",
    "    agent.load_model_from_dict(weights)\n",
    "    return agent, args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69409383-f02b-4403-83e5-5956cc7e8ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_episode(agent, args, seed, video_name=None, compute_log_std=False):\n",
    "    if video_name != None:\n",
    "        video = VideoRecorder('./ensemble_analysis')\n",
    "\n",
    "    env = make_envs(args, is_eval=True, use_state=True)\n",
    "    env.seed(seed)\n",
    "    obs = env.reset()\n",
    "    \n",
    "    if video_name != None:\n",
    "        video.init()\n",
    "        video.record(env)\n",
    "\n",
    "    episode_reward, episode_cost = 0, 0\n",
    "    actions = np.zeros(shape=(env._max_episode_steps, 4))\n",
    "    \n",
    "    log_std_list = np.zeros(shape=(env._max_episode_steps, 4))\n",
    "\n",
    "    for step in range(env._max_episode_steps):\n",
    "            with eval_mode(agent):\n",
    "                action = agent.select_action(obs)\n",
    "                actions[step] = action\n",
    "                if compute_log_std:\n",
    "                    obs_torch = torch.FloatTensor(obs).to(device).unsqueeze(0)\n",
    "                    mu, pi, log_pi, log_std = agent.model.actor(obs_torch, compute_log_pi=True)\n",
    "                    log_std_list[step] = log_std.detach().cpu().numpy()\n",
    "\n",
    "            next_obs, reward, done, info = env.step(action)\n",
    "            if video_name != None:\n",
    "                video.record(env)\n",
    "            episode_reward += reward\n",
    "            if args.cost != 'no_cost':\n",
    "                episode_cost += info['cost']\n",
    "\n",
    "            obs = next_obs\n",
    "    if video_name != None:\n",
    "        video.save(video_name)\n",
    "    print(f'Reward: {np.round(episode_reward, decimals=2)}, Cost: {np.round(episode_cost, decimals=2)}')\n",
    "    if compute_log_std:\n",
    "        return log_std_list\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8adae11a-bac9-49cd-a478-01a2fa015527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_success_rate(agent, args, seed, num_episodes=100, stochastic=False, low_cost_action=False):\n",
    "    env = make_envs(args, is_eval=True, use_state=args.agent == 'sac_state')\n",
    "    env.seed(seed)\n",
    "    \n",
    "    num_successes, reward_sum, cost_sum = 0, 0, 0\n",
    "    \n",
    "    for i in range(num_episodes): \n",
    "        obs = env.reset()\n",
    "\n",
    "        episode_reward, episode_cost = 0, 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "                with eval_mode(agent):\n",
    "                    if low_cost_action:\n",
    "                        action = agent.select_low_cost_action(obs)\n",
    "                    elif stochastic:\n",
    "                        action = agent.sample_action(obs)\n",
    "                    else:\n",
    "                        action = agent.select_action(obs)\n",
    "\n",
    "                next_obs, reward, done, info = env.step(action)\n",
    "                episode_reward += reward\n",
    "                if args.cost != 'no_cost':\n",
    "                    episode_cost += info['cost']\n",
    "\n",
    "                obs = next_obs\n",
    "        reward_sum += episode_reward\n",
    "        cost_sum += episode_cost\n",
    "        success = False\n",
    "        if info.get('is_success'):\n",
    "            num_successes += 1\n",
    "            success = True\n",
    "    return num_successes / num_episodes, reward_sum / num_episodes, cost_sum / num_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2922d3d-3d6a-4191-a3b4-35591853fd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652508"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = np.random.randint(1000000)\n",
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b77c9448-4f04-4638-944c-2b86aaa716ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 652508"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada6d51-54a2-4bb7-89e1-22a7a5b2247e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n",
      "Creating window glfw\n"
     ]
    }
   ],
   "source": [
    "barrier_results = pd.DataFrame(columns=['algo', 'alpha', 'success_rate', 'mean_reward', 'mean_cost'])\n",
    "base_path = '../../../output/final/fetch-push-barrier-drq-final/'\n",
    "\n",
    "for cost in ['reward', 'critic-train']:\n",
    "    for alpha in [0.5, 1.0]:\n",
    "        if alpha==0.5:\n",
    "            alpha_str = '05'\n",
    "        else:\n",
    "            alpha_str = '1'\n",
    "        path = base_path + f'drq_{cost}_alpha-{alpha_str}/'\n",
    "        agent, args = load_agent_and_args(path, device=torch.device('cuda'), model_name='model/latest_model.pt')\n",
    "        success_rate, mean_reward, mean_cost = calc_success_rate(agent, args, seed, 1000, False)\n",
    "        barrier_results.loc[len(barrier_results)] = [cost, alpha, success_rate, mean_reward, mean_cost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dad6567-d73a-4438-b29c-8c503b905a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "barrier_results.to_pickle('results/push-barrier-drq-final/eval_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a095b21-1798-448f-bf40-da4c96d84a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "barrier_results = pd.read_pickle('results/push-barrier-drq-final/eval_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2665456-6610-40c1-b5a8-d7be0c4dc835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>alpha</th>\n",
       "      <th>success_rate</th>\n",
       "      <th>mean_reward</th>\n",
       "      <th>mean_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reward</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-45.531786</td>\n",
       "      <td>2.424679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reward</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-52.985418</td>\n",
       "      <td>6.809077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>critic-train</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-40.041319</td>\n",
       "      <td>3.080384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>critic-train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-46.976916</td>\n",
       "      <td>2.219633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           algo  alpha  success_rate  mean_reward  mean_cost\n",
       "0        reward    0.5         0.003   -45.531786   2.424679\n",
       "3        reward    1.0         0.003   -52.985418   6.809077\n",
       "1  critic-train    0.5         0.003   -40.041319   3.080384\n",
       "2  critic-train    1.0         0.001   -46.976916   2.219633"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barrier_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08e61bc8-4c37-4293-b8b3-2bcec37cfbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "barrier_results.replace('critic-train', 'Safety Training', inplace=True)\n",
    "barrier_results.replace('reward', 'Reward Based', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "210c27f8-387f-4b07-95dc-91ab389385b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "barrier_results = barrier_results.rename(columns={'algo': 'Algorithm'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "218f410e-92f8-4c2b-8fad-d0029f046d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>alpha</th>\n",
       "      <th>success_rate</th>\n",
       "      <th>mean_reward</th>\n",
       "      <th>mean_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward Based</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-45.531786</td>\n",
       "      <td>2.424679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reward Based</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-52.985418</td>\n",
       "      <td>6.809077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Safety Training</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-40.041319</td>\n",
       "      <td>3.080384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Safety Training</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-46.976916</td>\n",
       "      <td>2.219633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Algorithm  alpha  success_rate  mean_reward  mean_cost\n",
       "0     Reward Based    0.5         0.003   -45.531786   2.424679\n",
       "3     Reward Based    1.0         0.003   -52.985418   6.809077\n",
       "1  Safety Training    0.5         0.003   -40.041319   3.080384\n",
       "2  Safety Training    1.0         0.001   -46.976916   2.219633"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barrier_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8e2b4c5-83b9-47eb-ba74-b374e5c33f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>success_rate</th>\n",
       "      <th>mean_reward</th>\n",
       "      <th>mean_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th>alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Reward Based</th>\n",
       "      <th>0.5</th>\n",
       "      <td>0.003</td>\n",
       "      <td>-45.531786</td>\n",
       "      <td>2.424679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.003</td>\n",
       "      <td>-52.985418</td>\n",
       "      <td>6.809077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Safety Training</th>\n",
       "      <th>0.5</th>\n",
       "      <td>0.003</td>\n",
       "      <td>-40.041319</td>\n",
       "      <td>3.080384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-46.976916</td>\n",
       "      <td>2.219633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       success_rate  mean_reward  mean_cost\n",
       "Algorithm       alpha                                      \n",
       "Reward Based    0.5           0.003   -45.531786   2.424679\n",
       "                1.0           0.003   -52.985418   6.809077\n",
       "Safety Training 0.5           0.003   -40.041319   3.080384\n",
       "                1.0           0.001   -46.976916   2.219633"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = barrier_results.groupby(['Algorithm', 'alpha']).mean()\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3d9939e-248b-487f-8587-1ff15f472886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrr}\n",
      "\\toprule\n",
      "                &     & Mean Success Rate & Mean Reward & Mean Cost \\\\\n",
      "Algorithm & alpha &                   &             &           \\\\\n",
      "\\midrule\n",
      "\\multirow{2}{*}{Reward Based} & 0.5 &             0.003 &     -45.532 &     2.425 \\\\\n",
      "                & 1.0 &             0.003 &     -52.985 &     6.809 \\\\\n",
      "\\cline{1-5}\n",
      "\\multirow{2}{*}{Safety Training} & 0.5 &             0.003 &     -40.041 &     3.080 \\\\\n",
      "                & 1.0 &             0.001 &     -46.977 &     2.220 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(grouped[['success_rate', 'mean_reward', 'mean_cost']].round(3).to_latex(header=['Mean Success Rate', 'Mean Reward', 'Mean Cost'], multirow=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7157f81f-8776-4e1c-81e3-2626a72998c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
